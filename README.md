# MidiMaker.pro - Project Documentation

**MidiMaker Generator** is a project focused on generating MIDI music compositions from textual descriptions leveraging the power of Large Language Models (LLMs). It addresses the challenge of maintaining musical coherence and structure in longer generated pieces by employing a sectional generation strategy.

![Project Concept Diagram](image.jpg)

The core concept involves:

1.  **Translating Ideas:** Converting high-level musical concepts (e.g., "a fast, optimistic electronic piece") into a structured plan.
2.  **Symbolic Representation:** Using a custom, compact text-based format to represent musical events (notes, chords, rests, tempo, etc.). This format is designed to be easily generated by LLMs and parsed by software.
3.  **Sectional Generation:** Breaking down the music generation process into distinct sections (e.g., Intro, Verse, Chorus). Each section is generated individually by the LLM, focusing on specific goals and maintaining context from previous sections.
4.  **Algorithmic Conversion:** Utilizing a Python script (`music.py`) to parse the concatenated symbolic text representation and synthesize it into a standard MIDI (`.mid`) file using the `pretty_midi` library.

The project aims to explore the potential of LLMs in creative musical tasks while providing a practical pipeline for generating structured musical outputs.

## 2. Features

-   **LLM-Powered Music Generation:** Uses Google's Gemini models (configurable) via the `google-generativeai` library to generate musical content.
-   **Text-to-Music Pipeline:** Implements a multi-step process from initial idea enrichment to final MIDI file generation.
-   **Sectional Generation:** Generates music section by section to improve coherence and structure in longer pieces.
-   **Compact Symbolic Music Format:** Defines and utilizes a concise text format for efficient LLM handling and robust parsing.
-   **MIDI File Output:** Generates standard MIDI files (`.mid`) compatible with Digital Audio Workstations (DAWs) and MIDI players.
-   **Configurable Parameters:** Allows setting the initial description, section structure/goals, LLM model, and default musical parameters (tempo, time signature, key) within the script.
-   **Instrument Support:** Supports various General MIDI instruments and includes mappings for common drum sounds.
-   **Musical Parameter Handling:** Parses and applies tempo, time signature, and key signature changes throughout the generated piece.
-   **Error Handling & Retries:** Includes basic retry logic for LLM API calls and warnings for parsing inconsistencies.

## 3. Architecture

The project follows a pipeline architecture, processing the musical idea through several stages:

1.  **LLM Enrichment:**

    -   **Input:** A brief, high-level text description of the desired music (`INITIAL_DESCRIPTION`).
    -   **Process:** An LLM (`call_gemini`) is prompted to elaborate on the initial description, suggesting specific musical parameters like key signature (`K:`), tempo (`T:`), time signature (`TS:`), primary instrumentation (`INST:`), mood, and potential structure.
    -   **Output:** A more detailed text description used as the overall plan. Default parameters (`DEFAULT_KEY`, `DEFAULT_TEMPO`, `DEFAULT_TIMESIG`) in the script may be updated based on this enriched output.

2.  **Sectional Symbolic Generation (Iterative):**

    -   **Input:** The overall plan (enriched description), specific goals for the current section (length in bars, musical function, relation to previous sections - defined in `SECTIONS`), the starting bar number, and optionally a summary of the previous section.
    -   **Process:** For each defined section (A1, B, A2, C...):
        -   An LLM (`call_gemini`) is prompted with the overall plan, section goals, starting bar number, previous section context, and the definition of the **Compact Symbolic Format**.
        -   The LLM generates the musical content for _only that section_ in the specified symbolic format.
    -   **Output:** A block of text representing the symbolic music for the current section.

3.  **Symbolic Concatenation:**

    -   **Input:** Symbolic text blocks generated for each section.
    -   **Process:** The text blocks are concatenated in order into a single string or file (`symbolic_music_[timestamp].txt`).
    -   **Output:** A complete symbolic representation of the entire musical piece.

4.  **Symbolic Parsing (`parse_symbolic_to_structured_data`):**

    -   **Input:** The concatenated symbolic text.
    -   **Process:** The `music.py` script parses the text line by line:
        -   Identifies commands (`INST`, `T`, `TS`, `K`, `BAR`, `N`, `C`, `R`).
        -   Manages musical state (current tempo, time signature, key, active instrument).
        -   Tracks time progression accurately, both globally and per instrument/track, handling bar synchronization.
        -   Converts symbolic representations (pitch names, duration symbols) into numerical values (MIDI pitch numbers, seconds).
        -   Handles instrument definitions (mapping names to GM programs, identifying drum tracks).
        -   Outputs warnings for parsing errors or timing inconsistencies.
    -   **Output:** Structured data containing note events, instrument definitions, tempo changes, time signature changes, and key signature changes, organized for MIDI creation.

5.  **MIDI File Generation (`create_midi_file`):**
    -   **Input:** The structured data from the parsing stage.
    -   **Process:** Uses the `pretty_midi` library:
        -   Initializes a `PrettyMIDI` object with the initial tempo.
        -   Adds tempo, time signature, and key signature change events at their respective times.
        -   Creates `Instrument` objects for each unique instrument/track combination, assigning General MIDI program numbers and handling the dedicated drum channel (Channel 10 / Index 9).
        -   Adds `Note` objects (pitch, velocity, start time, end time) to the corresponding instruments.
        -   Writes the complete structure to a `.mid` file (`generated_music_[timestamp].mid`).
    -   **Output:** A standard MIDI file.

### Key Components & Interactions:

-   **`music.py`:** The main script orchestrating the entire pipeline. It contains configuration, helper functions, pipeline stage implementations, parsing logic, and MIDI generation logic.
-   **LLM (Google Gemini):** External service accessed via the `google.generativeai` library. Used for creative tasks: enriching the description and generating symbolic music sections based on carefully crafted prompts.
    -   `call_gemini`: Handles API interaction, including retries and basic response validation.
-   **Compact Symbolic Format:** A crucial intermediate representation defined within the script (`SYMBOLIC_FORMAT_DEFINITION`) and used in prompts. It acts as the communication language between the LLM and the parser.
-   **Parser (`parse_symbolic_to_structured_data`):** Translates the LLM's symbolic output into a structured format suitable for MIDI generation. It handles time calculation based on tempo/time signature and manages musical context.
-   **MIDI Generator (`create_midi_file`):** Uses the `pretty_midi` library to synthesize the final MIDI file from the parser's structured data. It maps parsed information to standard MIDI events and structures.

## 4. Compact Symbolic Format

This format is designed for conciseness and ease of parsing, making it suitable for LLM generation.

-   `INST:<InstrumentName>`: Sets the active instrument context for subsequent notes/chords.
    -   Examples: `INST:Pno`, `INST:Gtr`, `INST:Bass`, `INST:Drums`, `INST:SynPad`
    -   Mapped to General MIDI programs via `INSTRUMENT_PROGRAM_MAP`.
-   `T:<BPM>`: Sets the tempo in Beats Per Minute.
    -   Example: `T:160`
-   `TS:<Numerator>/<Denominator>`: Sets the time signature.
    -   Example: `TS:4/4`
-   `K:<KeySignature>`: Sets the key signature. `pretty_midi` supports standard notation (e.g., Cmaj, Amin, F#dor).
    -   Example: `K:Cmin`, `K:Gmaj`
-   `BAR:<Number>`: Marks the beginning of a bar (measure). Used for synchronization and structure. Bar numbers should be sequential.
    -   Example: `BAR:1`, `BAR:9`
-   `N:<Track>:<Pitch>:<Duration>:<Velocity>`: Represents a single Note event.
    -   `Track`: An identifier for the musical part (e.g., `RH`, `LH`, `Melody`, `Bass`, `Drums`). Used with `INST` to define a unique track.
    -   `Pitch`: Standard musical notation (e.g., `C4`, `F#5`, `Gb3`). Middle C is `C4`. For drums, use names mapped in `DRUM_PITCH_MAP` (e.g., `Kick`, `Snare`, `HHC`).
    -   `Duration`: Symbolic representation of note length:
        -   `W` (Whole), `H` (Half), `Q` (Quarter), `E` (Eighth), `S` (Sixteenth), `T` (Thirty-second).
        -   Append `.` for dotted notes (e.g., `Q.`, `E.`).
    -   `Velocity`: MIDI velocity (0-127), representing loudness.
    -   Example: `N:Melody:G5:E:95`
-   `C:<Track>:<[Pitches]>:<Duration>:<Velocity>`: Represents a Chord event (multiple notes starting simultaneously).
    -   `[Pitches]`: Comma-separated list of pitch names within square brackets.
    -   Example: `C:PnoLH:[C3,Eb3,G3]:H:60`
-   `R:<Track>:<Duration>`: Represents a Rest (silence) event for a specific track.
    -   Example: `R:Bass:W`

**Note:** The LLM must be explicitly instructed to use _only_ this format in the generation prompts. The parser (`parse_symbolic_to_structured_data`) is designed to interpret this specific syntax.

## 5. Design Considerations & Challenges

-   **LLM Prompt Engineering:** Crafting effective prompts is crucial for controlling the LLM's output quality, adherence to the symbolic format, musical coherence within sections, and smooth transitions between sections.
-   **Symbolic Format Robustness:** The current format captures essential elements but might need extensions for nuances like dynamics (crescendo/decrescendo), articulations (staccato, legato), pedal markings, or more complex rhythmic notations. Balancing expressiveness and simplicity is key.
-   **Musical Cohesion:** Ensuring a consistent musical style and logical development across independently generated sections remains challenging. Passing contextual summaries between section prompts helps but may not always guarantee seamless transitions.

## 6. Future Enhancements

-   **Enhanced Symbolic Format:** Add commands for gradual tempo/dynamic changes (`TempoCurve`, `DynCurve`), articulations (`Art:Staccato`), pedal markings (`Pedal:On/Off`), etc.
-   **Improved State Management:** Implement more sophisticated methods for passing detailed musical context (e.g., last few notes/chords, harmonic context) between sectional generation prompts instead of just textual summaries.
-   **User Interface:** Develop a simple GUI or Web UI for easier input of descriptions, section definitions, and triggering the generation process.
-   **Music Theory Constraints:** Explore incorporating basic music theory rules (e.g., voice leading, harmonic progressions) either via constraints in the LLM prompt or as post-processing steps on the symbolic output.
-   **Alternative LLMs/Libraries:** Adapt the pipeline to work with other LLMs or MIDI generation libraries.

# TODO
